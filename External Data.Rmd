---
title: "External Data"
output: html_document
---

# External Data
The theme of this notebook is acquiring 3rd party data. 3rd party data organizations are interested in include ecomomic data (often collected through government efforts), social media, web site scraping, and demographic (often provided for a fee through marketing organizations).

## Packages
The usual mechanism for obtaining 3rd party data is  

**httr**
https://cran.r-project.org/web/packages/httr/

**jsonlite**
https://cran.r-project.org/web/packages/jsonlite


## External Data Sources
# Financial
# BEA
# Twitter

###Financial
<hr> 


```{r External Data - Financial}

library(quantmod)      # retrieve financial data (used for function via getSymbols) (masks as.Date from base R) 
library(broom)         # allows manipulation of data for prep for ggplot2 (used for function tidy)
library(tidyr)         # allows manipulation of data for prep for ggplot2 (used for function spread)
library(dplyr)         # allows manipulation of data for prep for ggplot2 (used for function filter)

stock_data <- getSymbols(c("^DJI","^GSPC"),src='yahoo', from = "2019-09-01", to = "2020-04-01") # DJI = Dow Jones Industrial Index, GSPC = Standard and Poor's 500 Index
head(stock_data)
head(DJI)
dow_jones2 <- tidy(DJI) # tidy from broom package converts list to "long" data frame for DJI 
head(dow_jones2)
dow_jones <- spread(dow_jones2, series, value) # spread from tidyr; converts long to wide using series values for new columns; that is, turn series row values to new columns
head(dow_jones)
dim(dow_jones) # spread function broke rows into new columns, so fewer rows and more columns


```


###BEA
<hr> 
https://apps.bea.gov/api/_pdf/bea_web_service_api_user_guide.pdf
Starting page 16

BEA Data Sets (see https://www.bea.gov/open-data)
NIPA
NIUnderlingDetail
FixedAssets
MNE
GDPbyIndustry
ITA
IIP
InputOutput
UnderlyingGDPbyIndustry
Regional


% change in Real GDP, Annually and Quarterly for all years
```{r External Data - BEA}

library(httr) # https://cran.r-project.org/web/packages/httr/httr.pdf
library(jsonlite)


BEA_API_Key <- "33B8961E-CF26-47E4-83D3-D89E003D1881"
BEA_Data_Set_Name <- "NIPA" # also "NIUnderlingDetail", "FixedAssets", "MNE", "GDPbyIndustry", "ITA" , "IIP", "InputOutput" , "UnderlyingGDPbyIndustry"
BEA_Table_Name <- "T10101"
BEA_Year <- "2018"
BEA_Frequency = "A,Q"
BEA_Results_Type <- "JSON"

BEA_string <- paste0("https://apps.bea.gov/api/data/?&UserID=", 
                     BEA_API_Key, 
                     "&method=GetData", 
                     "&DataSetName=", BEA_Data_Set_Name, 
                     "&TableName=", BEA_Table_Name, 
                     "&Frequency=", BEA_Frequency,
                     "&Year=", BEA_Year, 
                     "&ResultFormat=", BEA_Results_Type)


BEA_response <- GET(BEA_string)
http_status(BEA_response) # Want code 200

BEA_response_txt <- content(BEA_response, "text")

BEA_response_JSON <- fromJSON(BEA_response_txt)

BEA_dataframe <- BEA_response_JSON$BEAAPI$Results$Data



GET("https://apps.bea.gov/api/data/?&UserID=33B8961E-CF26-47E4-83D3-D89E003D1881&method=GetData&DataSetName=NIPA&TableName=T10101&Frequency=A,Q&Year=ALL&ResultFormat=JSON")




```



###Twitter
<hr> 


```{r External Data - Twitter}

library(httpuv) # for browser based twitter authentication
library(rtweet) # https://cran.r-project.org/web/packages/rtweet/vignettes/auth.html; https://cran.r-project.org/web/packages/rtweet/vignettes/intro.html


# token <- create_token(
#   app = "candidate_analytics_program",
#   consumer_key = "YLJzyXFpKg1dCTa5uSMoLug8d",
#   consumer_secret = "oGNObSOY4Sv7F1ick1RnJACLVB4TPqm7hRUifuNP3kyd5u96Lf",
#   access_token = "1010711033034563584-0m5OonJTidYAexpvHYXLGkzaecdYWk",
#   access_secret = "vc8ZgZajov532yODmAd6M9ZKSPaT2Qowg2ukfxl2M9TiM")
# 
Kmax_number_of_tweets = 20
Ksearch_days_in_past = 3

twitter_token <- create_token(
   app = "candidate_analytics_program",
   consumer_key = "YLJzyXFpKg1dCTa5uSMoLug8d",
   consumer_secret = "oGNObSOY4Sv7F1ick1RnJACLVB4TPqm7hRUifuNP3kyd5u96Lf",
   access_token = "1010711033034563584-0m5OonJTidYAexpvHYXLGkzaecdYWk",
   access_secret = "vc8ZgZajov532yODmAd6M9ZKSPaT2Qowg2ukfxl2M9TiM")

#rsconnect::setAccountInfo(name='analytics-candidate-engine', token='28A9CAB73745A874127EDC4CD584E909', secret='ueWeW0ZbPSCK+YjcxMsMfNHNjybHGAunotdr2iKy')
#rsconnect::deployApp("C:/Users/orang/Google Drive/TCU/Center for DT/Congruent/Congruent")
# rsconnect::deployApp('C:/Users/orang/Google Drive/Congruent/Congruent')


tweet_search_string <- '"recurring revenue" OR "growth capital" OR acquisition OR buyout OR contract OR financing' # space for AND
rt <- search_tweets(
  q = tweet_search_string, 
  n = Kmax_number_of_tweets, # Up to 18000 every 15 minutes
  include_rts = FALSE, # Retweets = tweet generated by "retweet" (recycle arrows), not quotes entering "RT" into text of one's tweets
  lang = "en", # language: BCP 47 language identifier
  geocode = lookup_coords("usa"), # for geo enabled tweets
  retryonratelimit = FALSE) # If ask for > 18k if TRUE, will wait and resend request when eligible for next batch
# SAVE FILE INTO RDS? Table for history?
#rt$contract <- grepl(" contract ", rt$text, ignore.case = TRUE) # flag to indicate text include term 'contract'
rt_df <- data.frame(created_at = rt$created_at, text = rt$text, favorite_count = rt$favorite_count, retweet_count = rt$retweet_count)
rt_df$source <- "General"

NewsFromBW_tweets <- get_timeline("NewsFromBW", n = Kmax_number_of_tweets)
NewsFromBW_tweets_df <- data.frame(created_at = NewsFromBW_tweets$created_at, text = NewsFromBW_tweets$text, favorite_count = NewsFromBW_tweets$favorite_count, retweet_count = NewsFromBW_tweets$retweet_count)
NewsFromBW_tweets_df$source <- "NewsFromBW"

rt_df <- rbind(NewsFromBW_tweets_df, rt_df)
rt_df$text <- gsub(" contract", "<span class='searchterms'> contract</span>", rt$text)


```


